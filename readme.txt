readme.txt
----------
1) Install python 3.6
2) Install Anaconda 3
3) Use Jupyter notebook as editor and interpreter
4) Install rasa_nlu and other required libraries using the anaconda command prompt:

   pip install rasa_nlu
   pip install -r requirements_full.txt
   pip install -e .

5) Set up the processing pipeline for rasa_nlu by spaCY and sklearn, by executing the following commands from anaconda prompt:
   
   pip install rasa_nlu[spacy]
   python -m spacy download en_core_web_md

   Create a link for loading spaCY by using below command, please note that below command should be executed by running anaconda prompt as administrator:

   python -m spacy link en_core_web_md en

6) Put the GSUCSBot in rasa_nlu folder to make sure that the libraries are accessible to the modules.

7) Change directory to GSUCSBot on anaconda command prompt and run the following command to train the model:

   python -m rasa_nlu.train -c config.json

8) Run the following command to start the server:

   python -m rasa_nlu.server -c config.json -e luis

9) The server will start at port number 5000, to check if the server is running properly or not, open IE (Internet Explorer) browser window, and run the    following command:

   http://localhost:5000/parse?q=chair-person
   
   This command will display show the intent and the intent scores.

10) In anaconda command prompt, in directory GSUCSBot, execute the following command to start client:
   
    python client.py

11) The client will start running on port number 8080, to check if the client is running properly, open IE (Internet Explorer) browser window, and run the       following command:

    http://localhost:8080/

12) Start communicating with chatbot in the client chat window.

--

10,4,3,6,10,2,8,6,13,8,3,7,10,8,8,6,7,3,3,2,8,4,13,2,8,14,3,11,8,6,13,2,6,9,14,8,12,3,3,7,3,15,5,8,4,18,4,12,2,8,8,5,2,8,4,10,3,2,4,2,5,9,2,13,5,4,4,3,6,10,10,3,4,3,4,3,3,7,4,10,4,3,2,9,3,16,4,5,7,1,4,13,2,10,8,3,7,3,3,9,3,4,3,3,13,6,2,7,3,6,9,5,3,7,3,3,3,6,3,2

Job Title: IT Data System Analyst

Job Location: The Ohio State University

Position Status: Permanent, full time

Number of positions to be filled: 1

Job Summary:

The individual is responsible for the development and implementation of digital projects

related to various energy conservation measures that will enable us to provide high-value, custom fit energy solutions for the Ohio State Columbus campus. This program is a “start-up” business and this role is fitting for a driven, creative and ambitious individual that is excited to embrace the team culture of a successful start-up organization.

Responsibilities:

Implement the ENGIE Digital Platform that will connect building smart meters and building management systems with the distribution network (steam, chilled water, electrical) and current and future on-site generation resources (boiler and chiller plants, future renewable generation, etc.).
Update and integrate data sources and develop algorithms through machine learning to improve the accuracy of the energy forecast model.
Create alarms to capture the Energy Use Intensity (EUI) datapoints outside of confidence interval for on-campus buildings and develop root cause analysis study.
Participate in the continuous development of the digital platform through internal and/ or external resources. This requires drafting the project documents such as scope of work, schedule, budget, etc.
Analyze the effects of the Energy Conservation Measures (ECM) on the EUI to validate the guaranteed energy savings.
Maintain the website that serves as the public interface of the platform.
Provide direct support to the Program Managers on creating collaborative and behavioral ECM solutions such as mobile applications, student competitions, etc.
Maintain awareness on current and new technologies and analyze their applicability to the program.
Collaborate with ENGIE digital teams worldwide.
Requirements:

B.S. in Computer Science and Engineering or in related field.
2 to 5 years of experience in related field.
Database management: SQL and NoSQL.
Development languages: Java, JavaScript, HTML, CSS, Python, Matlab, R, Scala.
Knowledge in API Management.
Previous experience with energy projects is a plus.
Ability to exceed targets as an individual and as a team.
Knowledge of modern management tools in continuous improvement
Job Type: Full-time

Education:

Associate

--
Micfo
--

• 2+ years of data engineering experience
• Proficiency in Python is required (this is our primary language)
• Proficiency in SQL is required (we use PostgreSQL and Redshift)
• A keen attention to detail
• Experience with queues and/or streams (we primarily use AWS SNS + SQS)
• Experience with key-value stores (we primarily use Redis and DynamoDB)
• Experience with a large-scale framework (e.g., Spark) is a plus

• Experience with any/all of Go, Scala, Java, or Ruby is a major plus
• A Bachelor’s Degree in a technical field or equivalent work experience

--

Sophia Lawhead = To do written exam
Cogo Labs = 1 More Week
Sam's club
--
Ying Fu
Logic 20/20 Interview = Wednesday
Acuitas Health = Thursday
--
Indeed, Glassdoor, Linkedin, Monster, Dice, Handshake
Data Science, Data Engineer, Data Analytics, Machine Learning, Deep Learning
Software Engineer, Associate, Junior, New Grad, Fresh Grad, recent grad, entry level
Big Data, programmer, developer, intern, coder, DevOps, cloud, Database

--

Sum: source_id
Unique
Sort
Top 4
--

I was facing issues while working on a recent project, the files I was dealing with were 3.03 TB each and were zipped, my pyspark program was failing with java heap error, so I coded a shell script to unzip the zipped files and then only extract the columns which I actually needed in the program also, I split the large files into smaller files and then input those files one at a time to the PySpark Program, which got me the results I wanted.
--

https://www.indeed.com/jobs?q=data%20science&sort=date&radius=25&start=40&vjk=319b26f363c77024
 Niche

Hi Rajani, 

Following up for the position of Data Engineering intern.  I found this position and the work which it has to offer interesting, I wanted to inquire about the status of your decision.

Looking forward to hear from you soon.

Thanks & Regards, 
Saurabh Gupta

20000 sq ft
10 cr + 5 cr + 3 cr + 4-5 crores
Bopal Amli Road pushpak bunglows
22 cr
--

Minimum 3 years of industry experience 
Excellent communication skills, whether through prose or data visualization 
Experience with software design & architecture 
Proficiency at the command line 
Commitment to data integrity and data management best practices 

Preferred qualifications:
Literacy in SQL, R, and/or Ruby (much of our existing infrastructure is written with these) 
A broad base of knowledge in scripting and system administration 
Experience working with AWS 
Experience with, or an enthusiasm to learn, Python, Spark, and surrounding ecosystem
   


   